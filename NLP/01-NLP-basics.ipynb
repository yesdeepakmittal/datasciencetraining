{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OHUreJUYMCM",
        "outputId": "f77dc971-1a70-479b-e8af-18a9703eeccd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hi, my name is Deepak Mittal and I am 24 years old.',\n",
              " 'I currently work as a Data Scientist and I am originally from India.',\n",
              " 'In my free time, I enjoy reading books.',\n",
              " \"It's nice to meet you!\"]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "# nltk.download('punkt')\n",
        "\n",
        "myself = \"Hi, my name is Deepak Mittal and I am 24 years old. \\\n",
        "          I currently work as a Data Scientist and I am originally from India. \\\n",
        "          In my free time, I enjoy reading books. It's nice to meet you!\"\n",
        "\n",
        "sent_tokenize(myself)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUhw3aOIadkt",
        "outputId": "be276deb-0e5d-42cf-88bf-af49077d3e66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hi',\n",
              " ',',\n",
              " 'my',\n",
              " 'name',\n",
              " 'is',\n",
              " 'Deepak',\n",
              " 'Mittal',\n",
              " 'and',\n",
              " 'I',\n",
              " 'am',\n",
              " '24',\n",
              " 'years',\n",
              " 'old',\n",
              " '.']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "word_tokenize(sent_tokenize(myself)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2_7_-yIcF4-",
        "outputId": "e2f5b6a4-59ad-4dca-d75c-31755812ca1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I', \"can't\", 'give', 'up']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import regexp_tokenize\n",
        "\n",
        "text = \"I can't give up!\"\n",
        "pattern = \"[\\w']+\"\n",
        "regexp_tokenize(text = text,pattern=pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nggmWXuej7mu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I', \"can't\", 'give', 'up']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "whitespace_pattern = \"\\s+\"\n",
        "text = \"I can't give up!\"\n",
        "regexp_tokenize(text = text,pattern=pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"Girl: Hey, how's it going?\",\n",
              " 'Boy: Not too bad, how about you?',\n",
              " \"Girl: I'm good, thanks for asking.\",\n",
              " 'What have you been up to lately?',\n",
              " 'Boy: Not much, just working and hanging out with friends.']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training a custom tokenizer\n",
        "\n",
        "from nltk.tokenize import PunktSentenceTokenizer #uses unsupervised approach\n",
        "from nltk.corpus import webtext\n",
        "\n",
        "# nltk.download('webtext')\n",
        "# text = webtext.raw('./chatgpt-generated-text.txt')\n",
        "with open('./chatgpt-generated-text.txt', 'r') as fp:\n",
        "    text = fp.read()\n",
        "\n",
        "sent_tokenizer = PunktSentenceTokenizer(text)\n",
        "sent_tokenizer.tokenize(text)[:5]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['arabic',\n",
              " 'azerbaijani',\n",
              " 'basque',\n",
              " 'bengali',\n",
              " 'catalan',\n",
              " 'chinese',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'greek',\n",
              " 'hebrew',\n",
              " 'hinglish',\n",
              " 'hungarian',\n",
              " 'indonesian',\n",
              " 'italian',\n",
              " 'kazakh',\n",
              " 'nepali',\n",
              " 'norwegian',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'slovene',\n",
              " 'spanish',\n",
              " 'swedish',\n",
              " 'tajik',\n",
              " 'turkish']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "# nltk.download('stopwords')\n",
        "stopwords.fileids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aadi',\n",
              " 'aaj',\n",
              " 'aap',\n",
              " 'aapne',\n",
              " 'aata',\n",
              " 'aati',\n",
              " 'aaya',\n",
              " 'aaye',\n",
              " 'ab',\n",
              " 'abbe',\n",
              " 'abbey',\n",
              " 'abe',\n",
              " 'abhi',\n",
              " 'able',\n",
              " 'about',\n",
              " 'above',\n",
              " 'accha',\n",
              " 'according',\n",
              " 'accordingly']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stopwords.words('hinglish')[:20]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Synsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('machine.n.01'),\n",
              " Synset('machine.n.02'),\n",
              " Synset('machine.n.03'),\n",
              " Synset('machine.n.04'),\n",
              " Synset('machine.n.05'),\n",
              " Synset('car.n.01'),\n",
              " Synset('machine.v.01'),\n",
              " Synset('machine.v.02')]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import wordnet\n",
        "# nltk.download('wordnet')\n",
        "\n",
        "word = 'machine'\n",
        "syn = wordnet.synsets(word)\n",
        "syn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 []\n",
            "1 ['the boxer was a magnificent fighting machine']\n",
            "2 ['the war machine']\n",
            "3 []\n",
            "4 ['he was endorsed by the Democratic machine']\n",
            "5 ['he needs a car to get to work']\n",
            "6 []\n",
            "7 ['The Americans were machining while others still hand-made cars']\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(syn)):\n",
        "    print(i,syn[i].examples())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'machine.n.01'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "syn[0].name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 --- Synset('machine.n.01') --- any mechanical or electrical device that transmits or modifies energy to perform or assist in the performance of human tasks\n",
            "1 --- Synset('machine.n.02') --- an efficient person\n",
            "2 --- Synset('machine.n.03') --- an intricate organization that accomplishes its goals efficiently\n",
            "3 --- Synset('machine.n.04') --- a device for overcoming resistance at one point by applying force at some other point\n",
            "4 --- Synset('machine.n.05') --- a group that controls the activities of a political party\n",
            "5 --- Synset('car.n.01') --- a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
            "6 --- Synset('machine.v.01') --- turn, shape, mold, or otherwise finish by machinery\n",
            "7 --- Synset('machine.v.02') --- make by machinery\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(syn)):\n",
        "    print(i,'---',syn[i],'---',syn[i].definition())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Synset.pos of Synset('machine.n.01')>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "syn[0].pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('computer.n.01'), Synset('calculator.n.01')]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordnet.synsets('computer', pos='n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Lemma('machine.n.01.machine')]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "syn[0].lemmas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computer\n",
            "computing_machine\n",
            "computing_device\n",
            "data_processor\n",
            "electronic_computer\n",
            "information_processing_system\n",
            "calculator\n",
            "reckoner\n",
            "figurer\n",
            "estimator\n",
            "computer\n"
          ]
        }
      ],
      "source": [
        "# all synonyms of a word\n",
        "for s in wordnet.synsets('computer'):\n",
        "    # print(l.lemmas())\n",
        "    for l in s.lemmas():\n",
        "        print(l.name())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "roughen\n",
            "rough\n",
            "rough\n",
            "staccato\n",
            "rough\n"
          ]
        }
      ],
      "source": [
        "# all antonyms of a word\n",
        "for s in wordnet.synsets('smooth'):\n",
        "    for l in s.lemmas():\n",
        "        for a in l.antonyms():\n",
        "            print(a.name())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9411764705882353"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Word similarity\n",
        "\n",
        "w1 = wordnet.synset('computer.n.01')\n",
        "w2 = wordnet.synset('machine.n.01')\n",
        "\n",
        "w1.wup_similarity(w2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "dbfb93579cd233f61bf7b1160072e941f3a008209323d76924e71308a0086e35"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
